# 프로젝트 간단 설명

<눈치 코치 캐치> 프로젝트 진행 과정에서 작업한 일들에 대한 간단한 설명입니다.

- [Canvas API](#Canvas-API)
  - [그림 그리기 기능](#그림-그리기-기능)
  - [floodfill](#floodfill)
  - [Canvas이벤트 핸들러](#Canvas이벤트-핸들러)
- [webRTC](#webRTC)
  - [how to connect?](#how-to-connect)
  - [소스 코드 해석](#소스-코드-해석)
  - [다른 유저 음소거](#다른-유저-음소거)
  - [내 마이크 음소거](#내-마이크-음소거)
- [게임 진행 메인 로직](#게임-진행-메인-로직)

## Canvas API

게임 진행 과정에서 가장 중요한 그림판을 구현하기 위해 Canvas API를 사용했습니다.
<b>종종 보이는 GAEventTrack은 데이터를 수집하기 위해 적용시킨 google analytics입니다.</b>

### 그림 그리기 기능

[ 가장 먼저, 그림판의 context를 초기화하는 hook입니다. ](https://github.com/GosuEE/trys-ketch-client/blob/dev/src/hooks/useCtx.jsx)

그림을 그리는 과정에서 변할 수 있는 context들을 초기 상태로 바꿔줍니다.

***

[ 그림을 그리는 과정에서 사용되는 다양한 함수들입니다. ](https://github.com/GosuEE/trys-ketch-client/blob/dev/src/utils/paintUtils.js)

```javascript
const startDrawing = (setIsDrawing) => {
  setIsDrawing(true);
};

const finishDrawing = (setIsDrawing) => {
  setIsDrawing(false);
};
```

isDrawing state를 변경시켜주는 함수입니다.

***

```javascript
const drawing = (ctx, isDrawing, { nativeEvent }) => {
  const { offsetX, offsetY } = nativeEvent;
  if (ctx) {
    if (!isDrawing) {
      ctx.beginPath();
      ctx.moveTo(offsetX, offsetY);
    } else {
      ctx.lineTo(offsetX, offsetY);
      ctx.stroke();
    }
  }
};
```

선을 그리는 함수입니다. drawing이 true면 lineTo로 그림을 그리고, false면 moveTo로 위치만 이동시킵니다.

***

```javascript
function setThickness(pixel, canvasRef, setCtx, eventState) {
  const context = canvasRef.current.getContext('2d');
  if (eventState !== EVENT_STATE.ERASEING) context.globalCompositeOperation = 'source-over';
  context.lineWidth = pixel;
  setCtx(context);
  GAEventTrack(GAEventTypes.Category.paintTool, GAEventTypes.Action.paintTool.Thickness);
}

function setColor(c, canvasRef, setCtx) {
  const context = canvasRef.current.getContext('2d');
  context.globalCompositeOperation = 'source-over';
  context.strokeStyle = c;
  setCtx(context);
  GAEventTrack(GAEventTypes.Category.paintTool, GAEventTypes.Action.paintTool.color, c);
}
```

선의 굵기와 색을 바꾸는 함수들입니다. 굵기와 색상은 상수로 따로 빼놓았습니다.

***

```javascript
function setEraser(canvasRef, setEventState, setCtx) {
  const context = canvasRef.current.getContext('2d');
  context.globalCompositeOperation = 'destination-out';
  context.strokeStyle = 0;
  setEventState(EVENT_STATE.ERASEING);
  setCtx(context);
  GAEventTrack(GAEventTypes.Category.paintTool, GAEventTypes.Action.paintTool.erase);
}
```

그림 그리는 상태를 eraser로 만드는 함수입니다.
globalCompositeOperation을 destination-out으로 만들어 새롭게 그리는 선과 겹치는 기존의 그림을 모두 삭제시킵니다. 또한 선의 색상을 0(투명)으로 만듭니다. #ffffff로 만드는 것과는 조금 다릅니다.

***

```javascript
function undo(historyPointer, history, ctx) {
  if (historyPointer.current === 0) return;
  if (historyPointer.current === history.length)
    history.push(ctx.getImageData(0, 0, ctx.canvas.width, ctx.canvas.height));
  historyPointer.current -= 1;
  const img = history[historyPointer.current];
  ctx.putImageData(img, 0, 0);
}

function redo(historyPointer, history, ctx) {
  if (historyPointer.current >= history.length - 1) return;
  historyPointer.current += 1;
  const img = history[historyPointer.current];
  ctx.putImageData(img, 0, 0);
}
```

그림판을 undo, redo하는 함수입니다.
undo와 redo의 구현은 이렇게 되어있습니다.

1. Canvas의 onMousedown속성에 현재의 Canvas의 ImageDate를 history배열에 저장시키는 코드를 추가합니다. 또한 mousedown 이벤트가 발생하면 이후의 history배열을 삭제시킵니다.

```javascript
history.push(ctx.getImageData(0, 0, ctx.canvas.width, ctx.canvas.height));
historyPointer.current += 1;
history.splice(historyPointer.current);
```

2. undo를 눌렀을 때 historyPointer를 1 감소시키고 해당하는 ImageData를 canvas의 context에 put합니다.

3. redo를 누르면 historyPointer를 1 증가시키고 위와 같이 작동합니다.

### floodfill

그림판의 페인트통과 같은 기능을 하는 알고리즘입니다.(주어진 특정 영역을 같은 색으로 칠함)
[ 전체 소스코드 ](https://github.com/GosuEE/trys-ketch-client/blob/dev/src/utils/floodFill.js)

```javascript
const stack = [x, y];
let stPtr = 2;
const dx = [0, -1, +1, 0];
const dy = [-1, 0, 0, +1];
```

가장 먼저, 픽셀의 위치를 담을 스택과 포인터, dx, dy를 정의합니다.

```javascript
const imageData = ctx.getImageData(0, 0, w, h);
const imgData = new Uint32Array(imageData.data.buffer);

// floodfill을 시작할 fixel의 color
const hitColor = getPixelColor(imgData, x, y);

// 해당 fixel이 이전에 색칠되지 않았으면 색상값은 white(0xffffffff)가 아니라 0입니다.
// 따라서 색상값이 0인 경우는 white로 취급하여 처리했습니다.
const hitHex = hitColor === 0 ? 0xffffffff : hitColor;
```

현재 canvas의 imagedata를 가져오고 색상을 설정합니다.

```javascript
const hitA = hitHex & 0xff000000;
const hitG = hitHex & 0x00ff0000;
const hitB = hitHex & 0x0000ff00;
const hitR = hitHex & 0x000000ff;
```

색상은 각 8비트의 AGBR형태의 32비트로 이루어져있습니다. 성능의 향상을 위해 비트연산자로 각 RGBA값을 추출했습니다.

```javascript
while (stPtr) {
    const curPointY = stack[--stPtr];
    const curPointX = stack[--stPtr];

    for (let i = 0; i < 4; i += 1) {
      const nextPointX = curPointX + dx[i];
      const nextPointY = curPointY + dy[i];

      if (nextPointX < 0 || nextPointY < 0 || nextPointX >= w || nextPointY >= h) {
        continue;
      }

      const nPO = nextPointY * w + nextPointX; // nextPointOffset

      const hex = imgData[nPO] === 0 ? 0xffffffff : imgData[nPO];

      // imgData의 값은 0xffffffff와 같은 16진수입니다.
      // 상위 비트부터 ABGR의 값을 나타냅니다.
      // 즉, 0xff(A)ff(B)ff(G)ff(R)을 의미합니다.
      // 따라서 RGBA값에 해당하는 비트를 and연산자로 마스킹해서 오른쪽으로 shift해 RGBA값을 사용했습니다.
      const A = (hitA - (hex & 0xff000000)) >> 24;
      const G = (hitG - (hex & 0x00ff0000)) >> 16;
      const B = (hitB - (hex & 0x0000ff00)) >> 8;
      const R = (hitR - (hex & 0x000000ff)) >> 0;

      if (imgData[nPO] === fillColor) {
        continue;
      }

      if (
        R > -TOLERANCE &&
        R < TOLERANCE &&
        G > -TOLERANCE &&
        G < TOLERANCE &&
        B > -TOLERANCE &&
        B < TOLERANCE &&
        A > -TOLERANCE &&
        A < TOLERANCE
      ) {
        // RGBA값의 표준편차를 구해 if문의 condition으로 사용 할 수도 있지만, 루트 연산이 성능상 좋지 않을 것 같습니다.
        // 따라서 일일이 TOLERANCE값과 비교했습니다.
        imgData[nPO] = fillColor;

        stack[stPtr++] = nextPointX;
        stack[stPtr++] = nextPointY;
      }
    }
  }
```

반복문의 시작입니다. 포인터가 0이 될 때까지 실행합니다.

```javascript
const curPointY = stack[--stPtr];
const curPointX = stack[--stPtr];
```

포인터의 초기값은 2이므로 반복문 시작시에 포인터는 0이되고, x와 y의 위치가 저장됩니다.

```javascript
for (let i = 0; i < 4; i += 1) {
      const nextPointX = curPointX + dx[i];
      const nextPointY = curPointY + dy[i];
```

for문이 시작됩니다. dx와 dy에 저장되어있는 값에 따라 다음 x와 y의 좌표는 아래, 왼쪽, 오른쪽, 위가 됩니다.

```javascript
if (nextPointX < 0 || nextPointY < 0 || nextPointX >= w || nextPointY >= h) {
	continue;
}
```

만일 좌표가 범위를 넘으면 continue합니다.

```javascript
const nPO = nextPointY * w + nextPointX; // nextPointOffset

const hex = imgData[nPO] === 0 ? 0xffffffff : imgData[nPO];

// imgData의 값은 0xffffffff와 같은 16진수입니다.
// 상위 비트부터 ABGR의 값을 나타냅니다.
// 즉, 0xff(A)ff(B)ff(G)ff(R)을 의미합니다.
// 따라서 RGBA값에 해당하는 비트를 and연산자로 마스킹해서 오른쪽으로 shift해 RGBA값을 사용했습니다.
const A = (hitA - (hex & 0xff000000)) >> 24;
const G = (hitG - (hex & 0x00ff0000)) >> 16;
const B = (hitB - (hex & 0x0000ff00)) >> 8;
const R = (hitR - (hex & 0x000000ff)) >> 0;
```

현재 pixel의 RGBA값과 클릭한 픽셀의 RGBA값의 차이를 비교합니다. 굳이 차이를 비교한 이유는, 칠해야 하는 픽셀의 값이 정수값의 픽셀 사이에 위치하게 되면 Canvas API가 해당 픽셀의 RGBA값을 자체적으로 보정합니다.

따라서 해당 픽셀들에는 floodfill알고리즘이 적용되지 않으므로, RGBA값이 특정한 범위 이내면 알고리즘을 적용시키기 위해 차이를 비교했습니다.

```javascript
if (imgData[nPO] === fillColor) {
	continue;
}
```

색상이 같으면 진행하지 않습니다.

```javascript
if (
R > -TOLERANCE &&
R < TOLERANCE &&
G > -TOLERANCE &&
G < TOLERANCE &&
B > -TOLERANCE &&
B < TOLERANCE &&
A > -TOLERANCE &&
A < TOLERANCE
) {
// RGBA값의 표준편차를 구해 if문의 condition으로 사용 할 수도 있지만, 루트 연산이 성능상 좋지 않을 것 같습니다.
// 따라서 일일이 TOLERANCE값과 비교했습니다.
	imgData[nPO] = fillColor;

	stack[stPtr++] = nextPointX;
	stack[stPtr++] = nextPointY;
}
```

RGBA값이 해당 범위 이내면, 색을 칠하고 다음 x와 y의 좌표를 스택에 추가합니다.

### Canvas이벤트 핸들러

[ 해당 소스 코드 파일입니다. ](https://github.com/GosuEE/trys-ketch-client/blob/dev/src/components/painting/CanvasWrapper.jsx)

```javascript
<Canvas
  isSubmitted={isSubmitted}
  ref={canvasRef}
  onClick={(event) => {
    if (eventState === EVENT_STATE.DRAWING || eventState === EVENT_STATE.ERASEING)
      drawCircle(ctx, event);
  }}
  onMouseDown={(event) => {
    history.push(ctx.getImageData(0, 0, ctx.canvas.width, ctx.canvas.height));
    historyPointer.current += 1;
    history.splice(historyPointer.current);
    if (eventState === EVENT_STATE.DRAWING || eventState === EVENT_STATE.ERASEING) {
      startDrawing(setIsDrawing);
    }
    if (eventState === EVENT_STATE.FILL) {
      fill(canvasRef, setCtx, ctx, event);
    }
  }}
  onMouseUp={() => {
    if (eventState === EVENT_STATE.DRAWING || eventState === EVENT_STATE.ERASEING) {
      finishDrawing(setIsDrawing);
    }
  }}
  onMouseMove={(event) => {
    if (eventState === EVENT_STATE.DRAWING || eventState === EVENT_STATE.ERASEING) {
      drawing(ctx, isDrawing, event);
    }
  }}
  onMouseLeave={() => {
    if (eventState === EVENT_STATE.DRAWING || eventState === EVENT_STATE.ERASEING) {
      finishDrawing(setIsDrawing);
    }
  }}
/>
```

현재 event의 상태를 'eraser', 'drawing', 'fill'로 나누어 해당 state마다 다른 함수가 호출되게 구현했습니다.

## webRTC

[ 시그널링 서버와 통신해 P2P webRTC연결을 진행하는 소스코드입니다. ](https://github.com/GosuEE/trys-ketch-client/blob/dev/src/components/webRTC/AudioCall.tsx)

### how to connect?

webRTC는 다음과 같은 절차를 밟아 진행됩니다.

1. 각 브라우저가 P2P 커뮤니케이션에 동의

2. 서로의 주소를 공유

3. 보안 사항 및 방화벽 우회

4. 멀티미디어 데이터를 실시간으로 교환

일반적인 웹 환경에서는 2번과 3번 문제를 해결하기는 조금 어렵습니다. webRTC는 브라우저에서 작동되기 때문에 외부에서 접근할 수 있는 주소가 없기 때문입니다. 따라서 통신 설정 초기 단계에서는 연결을 중재할 수 있는 서버가 필요합니다.

<b>TURN, STUN</b>

일반적인 컴퓨터에는 공인 IP가 할당되어있지 않습니다. 방화벽이나 NAT, DHCP 때문입니다. 일반적인 환경에서는 라우터가 NAT역할을 하여 내부 네트워크의 사설 IP들을 적절히 매핑시켜줍니다. 따라서 두 브라우저가 직접 통신을 하기 위해서는 현재 연결된 라우터의 공인 IP주소와 포트를 먼저 알아야합니다.

하지만 어떤 라우터들은 방화벽 설정이 되어있어 특정 주소나 포트와의 연결을 차단합니다. 이처럼 라우터를 통과하여 연결할 방법을 찾는 과정을 NAT traversal이라고 합니다. webRTC는 이를 STUN, TURN서버를 통해 구현하였습니다.

STUN방식은 단말이 자신의 공인 IP주소와 포트를 확인하는 프로토콜입니다. webRTC연결을 시작하기 전에 STUN서버를 향해 요청을 보내면 STUN서버는 NAT뒤에 있는 Peer들이 연결할 수 있도록 공인 IP주소와 포트를 찾아줍니다.

그러나 모든 단말들이 항상 자신의 정보를 찾아낼 수는 없습니다. 이런 경우 TURN이라는 서버를 매개로 통신하게됩니다. TURN방식의 경우 서버가 네트워크 미디어를 중개하게 되므로 진정한 P2P통신은 아닙니다. 따라서 최후의 수단으로 선택해야 합니다.

<b>ICE, Candidate</b>

STUN, TURN서버를 이용해 획득한 IP주소, 프로토콜, 포트의 조합으로 구성된 연결 가능한 네트워크 주소들을 Candidate라고 부릅니다. 그리고 위와 같은 과정을 후보 찾기라고 부릅니다.

후보들을 수집하면 일반적으로 3개의 주소를 얻게 됩니다.

1. 자신의 사설 IP와 포트 넘버

2. 자신의 공인 IP와 포트 넘버 (STUN, TURN 서버로부터 획득 가능)

3. TURN 서버의 IP와 포트 넘버 (TURN 서버를 사용하는 경우)

이 모든 과정은 ICE(Interactive Connectivity Establishment)라는 프레임워크 위에서 이루어집니다. ICE는 두 개의 단말이 P2P연결을 가능하게 하도록 최적의 경로를 찾아주는 프레임워크입니다.

즉, ICE 프레임워크가 STUN 또는 TURN서버를 이용해 상대방과 연결 가능한 후보들을 갖고 있게 됩니다. 이제 주소는 다 알았으니, 미디어와 관련된 정보를 교환해야 합니다.

<b>SDP</b>

SDP(Session Description Protocol)는 webRTC에서 스트리밍 미디어의 해상도나 형식, 코덱등의 초기 인수를 설명하기 위해 채택한 프로토콜입니다.

발행/ 구독 모델과 유사한 제안/응답 모델을 사용합니다. 어떤 피어가 미디어스트림을 교환할 것이라고 제안하면, 상대방으로부터 응답이 오기를 기다립니다.

응답을 받게 되면 각자의 피어가 수집한 ICE후보들에게 패킷을 보내고 가장 지연 시간이 적고 안정적인 경로를 결정합니다. 이렇게 최적의 ICE 후보가 선택되면 필요한 메타데이터와 IP주소, 포트, 미디어정보에 대한 피어간 합의가 완료되고 연결이 활성화됩니다.

만약 최선의 ICE 후보를 찾지 못한다면, 풀백으로 설정한 TURN서버를 사용합니다.

위 과정을 일컬어 시그널링이라고 부릅니다. 해당 프로젝트에서는 Spring boot로 시그널링 서버를 구현했으며, 서버와의 통신은 SockJS를 사용했습니다.

<b>출처: https://wormwlrm.github.io/2021/01/24/Introducing-WebRTC.html</b>

### 소스 코드 해석

```javascript
    pc.onicecandidate = (e) => {
      if (e.candidate) {
        socket.send(
          JSON.stringify({
            token,
            type: RTC_SOCKET_MSG.CANDIDATE,
            candidate: e.candidate,
            receiver: socketID,
          }),
        );
      }
    };
```

RTCPeerConnection객체에 ICECandidate 이벤트가 발생했을 때의 핸들러입니다.

시그널링 서버에 candidate메세지와 필요한 데이터를 전송합니다.

```javascript
  useEffect(() => {
    navigator.mediaDevices
      .getUserMedia({
        video: false,
        audio: true,
      })
      .then((stream) => {
        if (audioRef.current) audioRef.current.srcObject = stream;
        localStream = stream;
        getUserMediaState = MEDIA_STATE.FULFILLED;
      })
      .catch((error) => {
        getUserMediaState = MEDIA_STATE.REJECTED;
        toast.error('음성 채팅 연결 에러');
        toast.error('다른 유저들이 플레이어님의 말을 들을 수 없어요!');
      });
  }, []);
```

로컬 미디어 스트림을 가져오는 useState입니다.

해당 과정에서 여러가지 문제가 있었는데, 미디어 스트림을 연결하는 과정에서 유저의 동의를 구할 때 프로그램의 흐름이 멈춘다는 것입니다. 유저가 동의하지 않으면 소켓이 연결되지 않고 webRTC연결이 진행되지 않습니다.

따라서 해당 과정을 다른 useEffect훅으로 뺐습니다. 이런 경우에는 미디어 스트림을 허가/거부하지 않은 상태에서 피어 커넥션이 연결되기 때문에 로컬 미디어 스트림이 undefined인 상태라 다른 유저가 나의 목소리를 들을 수 없는 문제가 생겼습니다.

결과적으로는 다른 useEffect훅으로 빼는것은 유지한 채 피어커넥션을 생성하기 이전에 로컬 미디어스트림이 fullfill, 혹은 reject되지 않으면 잠시 흐름을 멈춰 유저가 허가/거부할때까지 기다리도록 구현했습니다.

```javascript
// 소켓이 연결되었을 때 실행
socketRef.current.onopen = async () => {
	socketRef.current?.send(JSON.stringify({ type: SOCKET_MSG.JOIN, room: id, token }));
};
```

소켓이 연결되면, 가장 먼저 시그널링 서버에 join 메세지를 보냅니다.

```javascript
	case RTC_SOCKET_MSG.ALL_USERS: {
          const { allUsers, sender } = data;
          dispatch(setID(sender));
          // 나를 제외했으므로 방에 나밖에 없으면 length는 0
          const len = allUsers.length;
          for (let i = 0; i < len; i += 1) {
            while (getUserMediaState === MEDIA_STATE.PENDING) {
              if (stop) return;
              await sleep(300);
            }
            // if (getUserMediaState === 'rejected') return;

            hasPcs = { ...hasPcs, [allUsers[i].id]: false };
            // i번째 유저와 나의 peer connection 생성
            createPeerConnection(allUsers[i].id, socketRef.current, localStream);

            while (!hasPcs[allUsers[i].id]) {
              if (stop) return;
              await sleep(100);
            }
            // allUsers에서 사용하는 peer connection, i번째 유저의 peer connection입니다.
            const allUsersPc: RTCPeerConnection = pcs[allUsers[i].id];

            // allUserPc가 존재하면
            if (allUsersPc) {
              // offer를 생성하고
              allUsersPc
                .createOffer({ offerToReceiveAudio: true, offerToReceiveVideo: false })
                .then((sdp) => {
                  // 상대방과의 peer connection에 내 sdp를 이용해 local description을 생성
                  allUsersPc.setLocalDescription(new RTCSessionDescription(sdp));
                  // signaling server에 i번째 유저에게 offer를 요청합니다.
                  socketRef.current?.send(
                    JSON.stringify({
                      type: RTC_SOCKET_MSG.OFFER,
                      sdp,
                      receiver: allUsers[i].id,
                    }),
                  );
                })
                .catch((error) => {});
            }
          }
          break;
        }

```

join 메세지를 받으면, 서버에서 현재 연결되어있는 모든 유저를 반환하는 allUsers라는 응답을 보냅니다.

그리고 allUsers에 담겨있는 모든 유저에게 PeerConnection을 생성합니다.

만약 피어 커넥션이 잘 생성됐으면, offer를 생성하고 sdp를 생성해 시그널링 서버에 offer를 sdp와 함께 보냅니다.

```javascript
	// 2. 상대방이 offer를 받으면
        case RTC_SOCKET_MSG.OFFER: {
          while (getUserMediaState === MEDIA_STATE.PENDING) {
            if (stop) return;
            await sleep(300);
          }

          hasPcs = { ...hasPcs, [data.sender]: false };
          // offer를 요청한 상대방과의 peer connection을 생성합니다.
          createPeerConnection(data.sender, socketRef.current, localStream);

          while (!hasPcs[data.sender]) {
            if (stop) return;
            await sleep(100);
          }

          // offer에서 사용하는 peer connection, offer를 요청한 상대방과의 peer connection 입니다.
          const offerPc: RTCPeerConnection = pcs[data.sender];
          if (offerPc) {
            // offer를 보낸 상대방의 sdp를 이용해 상대방의 remote discription을 생성합니다.
            offerPc.setRemoteDescription(new RTCSessionDescription(data.sdp)).then(() => {
              offerPc // answer를 생성하고
                .createAnswer({ offerToReceiveVideo: false, offerToReceiveAudio: true })
                .then((sdp) => {
                  // 나의 sdp를 이용해
                  // 내 local description을 설정하고
                  offerPc.setLocalDescription(new RTCSessionDescription(sdp));
                  // offer를 보낸 상대방에게 answer를 보냅니다.
                  socketRef.current?.send(
                    JSON.stringify({
                      token,
                      type: RTC_SOCKET_MSG.ANSWER,
                      sdp,
                      // answerSendID: newSocket.id,
                      receiver: data.sender,
                    }),
                  );
                })
                .catch((error) => {});
            });
          }
          break;
        }
```

offer를 받으면 offer를 보낸 상대에게 answer를 보냅니다.

```javacript
	case RTC_SOCKET_MSG.ANSWER: {
          // answer에서 사용하는 peer connection, answer를 보낸 상대방과의 peer connection 입니다.
          const answerPc: RTCPeerConnection = pcs[data.sender];
          // answerPc가 존재하면
          if (answerPc) {
            // answerPc의 remote description을 상대방의 sdp를 이용해 설정합니다.
            answerPc.setRemoteDescription(new RTCSessionDescription(data.sdp));
          }
          break;
        }

```

answer를 받으면 remote description을 상대방의 sdp를 이용하여 설정합니다.

```javascript
        case RTC_SOCKET_MSG.CANDIDATE: {
          while (!hasPcs[data.sender]) {
            if (stop) return;
            await sleep(100);
          }

          // candidate에서 사용하는 peer connection, candidate 요청을 보낸 상대방과의 peer connection 입니다.
          const candidatePc: RTCPeerConnection = pcs[data.sender];
          // candidatePc가 존재하면
          if (candidatePc) {
            // cadidate 요청을 보낸 상대방의 candidate 정보로 candidate를 추가합니다.
            candidatePc.addIceCandidate(new RTCIceCandidate(data.candidate)).then(() => {});
          }
          break;
        }
```

candidate 요청을 받으면 상대방의 candidate 정보로 candidate를 추가합니다.

```javascript
	// 유저가 연결을 종료하면
        case RTC_SOCKET_MSG.EXIT: {
          if (hasPcs[data.sender]) {
            // 해당 유저와의 peer connection을 종료하고
            pcs[data.sender].close();
            // pcs 배열에서 해당 user를 삭제합니다.
            delete pcs[data.sender];
          }
          // user state를 업데이트하고 리렌더링시킵니다.
          setUsers((oldUsers) => oldUsers.filter((user) => user.id !== data.sender));
          // dispatch(setMuteUsers(muteUsers.filter((user) => user.id !== data.sender)));
          break;
        }
        default:
          break;
      }
```

유저가 연결을 종료하면 users state에 해당 user를 삭제합니다.

### 다른 유저 음소거

```javascript
  useEffect(() => {
    const newMuteUsers: any = [];
    for (let i = 0; i < muteUser.length; i += 1) {
      for (let k = 0; k < users.length; k += 1) {
        if (muteUser[i].socketID === users[k].id) {
          const newMuteUser = { ...muteUser[i], pc: users[k].pc };
          newMuteUsers.push(newMuteUser);
          break;
        }
      }
    }

    dispatch(setConnectedMuteUser(newMuteUsers));
  }, [users, muteUser]);
```

다른 유저들을 음소거하기 위해서는 가장 먼저 현재 webRTC가 연결된 유저의 정보를 가져와야합니다. 
[ useMuteUser hook입니다. ](#https://github.com/GosuEE/trys-ketch-client/blob/dev/src/hooks/useMuteUser.jsx)

GameRoom에서 현재 같은 방에 존재하는 유저들을 서버에서 attendees라는 배열로 보내는데, 본인을 제외한 다른 유저들을 muteUser라는 이름으로 리덕스 스토어에 전역상태로 등록합니다.

그런 뒤 AudioCall컴포넌트에서 해당 상태를 가져와 현재 webRTC가 연결되어있는 유저들을 담고있는 state인 users와 비교해 연결된 유저들만 다시 connectedMuteUser라는 이름으로 전역상태로 등록합니다.

```javascript
function MuteUserList({ socketID }) {
  const users = useSelector((state) => state.mute.connectedUsers);
  return (
    <div>
      {users.length !== 0 && (
        <UserList>
          {users.map((v) => {
            return socketID !== v.socketID && <MuteUser key={v.socketID} user={v} />;
          })}
        </UserList>
      )}
    </div>
  );
}
```

이후 MuteUserList 컴포넌트에서 해당 전역상태를 가져와 렌더링시키고

```javascript
function MuteUser({ user }) {
  const { pc } = user;
  const [isSpeaking, setIsSpeaking] = useState(false);
  useObserveSpeaking(pc, setIsSpeaking);

  return (
    <UserWrapper>
      <User isSpeaking={isSpeaking}>{`${user.nickname}`}</User>
      <MuteButton socketID={user.socketID} isMuted={user.isMuted} />
    </UserWrapper>
  );
}
```

```javascript
function MuteButton({ socketID, isMuted }) {
  const dispatch = useDispatch();
  function onChangeMute() {
    dispatch(setMute({ socketID, isMuted: !isMuted }));
  }
  return isMuted ? (
    <Button onClick={() => onChangeMute()}>
      <Image src={micMute} alt="muted" />
    </Button>
  ) : (
    <Button onClick={() => onChangeMute()}>
      <Image style={{ marginRight: '2px' }} src={mic} alt="mic" />
    </Button>
  );
}
```

muteButton을 누르면 Audio컴포넌트의 해당 user를 mute함으로써 구현했습니다.

### 내 마이크 음소거

```javascript
function MuteButton({ socketID, isMuted }) {
  const dispatch = useDispatch();
  function onChangeMute() {
    dispatch(setMute({ socketID, isMuted: !isMuted }));
  }
  return isMuted ? (
    <Button onClick={() => onChangeMute()}>
      <Image src={micMute} alt="muted" />
    </Button>
  ) : (
    <Button onClick={() => onChangeMute()}>
      <Image style={{ marginRight: '2px' }} src={mic} alt="mic" />
    </Button>
  );
}
```

내 마이크 음소거는 간단합니다. 음소거 버튼 클릭시 전역 상태로 등록된 localMute를 바꿔주고, 만약 localMute가 true면 localStream의 track의 enabled 속성을 false로 바꾸어 구현했습니다.

## 게임 진행 메인 로직

















