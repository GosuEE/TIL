# 프로젝트 간단 설명

<눈치 코치 캐치> 프로젝트 진행 과정에서 작업한 일들에 대한 간단한 설명입니다.

- [Canvas API](#Canvas-API)
  - [그림 그리기 기능](#그림-그리기-기능)
  - [floodfill](#floodfill)
  - [Canvas이벤트 핸들러](#Canvas이벤트-핸들러)
- [webRTC](#webRTC)
  - [how to connect?](#how-to-connect)

## Canvas API

게임 진행 과정에서 가장 중요한 그림판을 구현하기 위해 Canvas API를 사용했습니다.
<b>종종 보이는 GAEventTrack은 데이터를 수집하기 위해 적용시킨 google analytics입니다.</b>

### 그림 그리기 기능

[ 가장 먼저, 그림판의 context를 초기화하는 hook입니다. ](https://github.com/GosuEE/trys-ketch-client/blob/dev/src/hooks/useCtx.jsx)

그림을 그리는 과정에서 변할 수 있는 context들을 초기 상태로 바꿔줍니다.

***

[ 그림을 그리는 과정에서 사용되는 다양한 함수들입니다. ](https://github.com/GosuEE/trys-ketch-client/blob/dev/src/utils/paintUtils.js)

```javascript
const startDrawing = (setIsDrawing) => {
  setIsDrawing(true);
};

const finishDrawing = (setIsDrawing) => {
  setIsDrawing(false);
};
```

isDrawing state를 변경시켜주는 함수입니다.

***

```javascript
const drawing = (ctx, isDrawing, { nativeEvent }) => {
  const { offsetX, offsetY } = nativeEvent;
  if (ctx) {
    if (!isDrawing) {
      ctx.beginPath();
      ctx.moveTo(offsetX, offsetY);
    } else {
      ctx.lineTo(offsetX, offsetY);
      ctx.stroke();
    }
  }
};
```

선을 그리는 함수입니다. drawing이 true면 lineTo로 그림을 그리고, false면 moveTo로 위치만 이동시킵니다.

***

```javascript
function setThickness(pixel, canvasRef, setCtx, eventState) {
  const context = canvasRef.current.getContext('2d');
  if (eventState !== EVENT_STATE.ERASEING) context.globalCompositeOperation = 'source-over';
  context.lineWidth = pixel;
  setCtx(context);
  GAEventTrack(GAEventTypes.Category.paintTool, GAEventTypes.Action.paintTool.Thickness);
}

function setColor(c, canvasRef, setCtx) {
  const context = canvasRef.current.getContext('2d');
  context.globalCompositeOperation = 'source-over';
  context.strokeStyle = c;
  setCtx(context);
  GAEventTrack(GAEventTypes.Category.paintTool, GAEventTypes.Action.paintTool.color, c);
}
```

선의 굵기와 색을 바꾸는 함수들입니다. 굵기와 색상은 상수로 따로 빼놓았습니다.

***

```javascript
function setEraser(canvasRef, setEventState, setCtx) {
  const context = canvasRef.current.getContext('2d');
  context.globalCompositeOperation = 'destination-out';
  context.strokeStyle = 0;
  setEventState(EVENT_STATE.ERASEING);
  setCtx(context);
  GAEventTrack(GAEventTypes.Category.paintTool, GAEventTypes.Action.paintTool.erase);
}
```

그림 그리는 상태를 eraser로 만드는 함수입니다.
globalCompositeOperation을 destination-out으로 만들어 새롭게 그리는 선과 겹치는 기존의 그림을 모두 삭제시킵니다. 또한 선의 색상을 0(투명)으로 만듭니다. #ffffff로 만드는 것과는 조금 다릅니다.

***

```javascript
function undo(historyPointer, history, ctx) {
  if (historyPointer.current === 0) return;
  if (historyPointer.current === history.length)
    history.push(ctx.getImageData(0, 0, ctx.canvas.width, ctx.canvas.height));
  historyPointer.current -= 1;
  const img = history[historyPointer.current];
  ctx.putImageData(img, 0, 0);
}

function redo(historyPointer, history, ctx) {
  if (historyPointer.current >= history.length - 1) return;
  historyPointer.current += 1;
  const img = history[historyPointer.current];
  ctx.putImageData(img, 0, 0);
}
```

그림판을 undo, redo하는 함수입니다.
undo와 redo의 구현은 이렇게 되어있습니다.

1. Canvas의 onMousedown속성에 현재의 Canvas의 ImageDate를 history배열에 저장시키는 코드를 추가합니다. 또한 mousedown 이벤트가 발생하면 이후의 history배열을 삭제시킵니다.

```javascript
history.push(ctx.getImageData(0, 0, ctx.canvas.width, ctx.canvas.height));
historyPointer.current += 1;
history.splice(historyPointer.current);
```

2. undo를 눌렀을 때 historyPointer를 1 감소시키고 해당하는 ImageData를 canvas의 context에 put합니다.

3. redo를 누르면 historyPointer를 1 증가시키고 위와 같이 작동합니다.

### floodfill

그림판의 페인트통과 같은 기능을 하는 알고리즘입니다.(주어진 특정 영역을 같은 색으로 칠함)
[ 전체 소스코드 ](https://github.com/GosuEE/trys-ketch-client/blob/dev/src/utils/floodFill.js)

```javascript
const stack = [x, y];
let stPtr = 2;
const dx = [0, -1, +1, 0];
const dy = [-1, 0, 0, +1];
```

가장 먼저, 픽셀의 위치를 담을 스택과 포인터, dx, dy를 정의합니다.

```javascript
const imageData = ctx.getImageData(0, 0, w, h);
const imgData = new Uint32Array(imageData.data.buffer);

// floodfill을 시작할 fixel의 color
const hitColor = getPixelColor(imgData, x, y);

// 해당 fixel이 이전에 색칠되지 않았으면 색상값은 white(0xffffffff)가 아니라 0입니다.
// 따라서 색상값이 0인 경우는 white로 취급하여 처리했습니다.
const hitHex = hitColor === 0 ? 0xffffffff : hitColor;
```

현재 canvas의 imagedata를 가져오고 색상을 설정합니다.

```javascript
const hitA = hitHex & 0xff000000;
const hitG = hitHex & 0x00ff0000;
const hitB = hitHex & 0x0000ff00;
const hitR = hitHex & 0x000000ff;
```

색상은 각 8비트의 AGBR형태의 32비트로 이루어져있습니다. 성능의 향상을 위해 비트연산자로 각 RGBA값을 추출했습니다.

```javascript
while (stPtr) {
    const curPointY = stack[--stPtr];
    const curPointX = stack[--stPtr];

    for (let i = 0; i < 4; i += 1) {
      const nextPointX = curPointX + dx[i];
      const nextPointY = curPointY + dy[i];

      if (nextPointX < 0 || nextPointY < 0 || nextPointX >= w || nextPointY >= h) {
        continue;
      }

      const nPO = nextPointY * w + nextPointX; // nextPointOffset

      const hex = imgData[nPO] === 0 ? 0xffffffff : imgData[nPO];

      // imgData의 값은 0xffffffff와 같은 16진수입니다.
      // 상위 비트부터 ABGR의 값을 나타냅니다.
      // 즉, 0xff(A)ff(B)ff(G)ff(R)을 의미합니다.
      // 따라서 RGBA값에 해당하는 비트를 and연산자로 마스킹해서 오른쪽으로 shift해 RGBA값을 사용했습니다.
      const A = (hitA - (hex & 0xff000000)) >> 24;
      const G = (hitG - (hex & 0x00ff0000)) >> 16;
      const B = (hitB - (hex & 0x0000ff00)) >> 8;
      const R = (hitR - (hex & 0x000000ff)) >> 0;

      if (imgData[nPO] === fillColor) {
        continue;
      }

      if (
        R > -TOLERANCE &&
        R < TOLERANCE &&
        G > -TOLERANCE &&
        G < TOLERANCE &&
        B > -TOLERANCE &&
        B < TOLERANCE &&
        A > -TOLERANCE &&
        A < TOLERANCE
      ) {
        // RGBA값의 표준편차를 구해 if문의 condition으로 사용 할 수도 있지만, 루트 연산이 성능상 좋지 않을 것 같습니다.
        // 따라서 일일이 TOLERANCE값과 비교했습니다.
        imgData[nPO] = fillColor;

        stack[stPtr++] = nextPointX;
        stack[stPtr++] = nextPointY;
      }
    }
  }
```

반복문의 시작입니다. 포인터가 0이 될 때까지 실행합니다.

```javascript
const curPointY = stack[--stPtr];
const curPointX = stack[--stPtr];
```

포인터의 초기값은 2이므로 반복문 시작시에 포인터는 0이되고, x와 y의 위치가 저장됩니다.

```javascript
for (let i = 0; i < 4; i += 1) {
      const nextPointX = curPointX + dx[i];
      const nextPointY = curPointY + dy[i];
```

for문이 시작됩니다. dx와 dy에 저장되어있는 값에 따라 다음 x와 y의 좌표는 아래, 왼쪽, 오른쪽, 위가 됩니다.

```javascript
if (nextPointX < 0 || nextPointY < 0 || nextPointX >= w || nextPointY >= h) {
	continue;
}
```

만일 좌표가 범위를 넘으면 continue합니다.

```javascript
const nPO = nextPointY * w + nextPointX; // nextPointOffset

const hex = imgData[nPO] === 0 ? 0xffffffff : imgData[nPO];

// imgData의 값은 0xffffffff와 같은 16진수입니다.
// 상위 비트부터 ABGR의 값을 나타냅니다.
// 즉, 0xff(A)ff(B)ff(G)ff(R)을 의미합니다.
// 따라서 RGBA값에 해당하는 비트를 and연산자로 마스킹해서 오른쪽으로 shift해 RGBA값을 사용했습니다.
const A = (hitA - (hex & 0xff000000)) >> 24;
const G = (hitG - (hex & 0x00ff0000)) >> 16;
const B = (hitB - (hex & 0x0000ff00)) >> 8;
const R = (hitR - (hex & 0x000000ff)) >> 0;
```

현재 pixel의 RGBA값과 클릭한 픽셀의 RGBA값의 차이를 비교합니다. 굳이 차이를 비교한 이유는, 칠해야 하는 픽셀의 값이 정수값의 픽셀 사이에 위치하게 되면 Canvas API가 해당 픽셀의 RGBA값을 자체적으로 보정합니다.

따라서 해당 픽셀들에는 floodfill알고리즘이 적용되지 않으므로, RGBA값이 특정한 범위 이내면 알고리즘을 적용시키기 위해 차이를 비교했습니다.

```javascript
if (imgData[nPO] === fillColor) {
	continue;
}
```

색상이 같으면 진행하지 않습니다.

```javascript
if (
R > -TOLERANCE &&
R < TOLERANCE &&
G > -TOLERANCE &&
G < TOLERANCE &&
B > -TOLERANCE &&
B < TOLERANCE &&
A > -TOLERANCE &&
A < TOLERANCE
) {
// RGBA값의 표준편차를 구해 if문의 condition으로 사용 할 수도 있지만, 루트 연산이 성능상 좋지 않을 것 같습니다.
// 따라서 일일이 TOLERANCE값과 비교했습니다.
	imgData[nPO] = fillColor;

	stack[stPtr++] = nextPointX;
	stack[stPtr++] = nextPointY;
}
```

RGBA값이 해당 범위 이내면, 색을 칠하고 다음 x와 y의 좌표를 스택에 추가합니다.

### Canvas이벤트 핸들러

[ 해당 소스 코드 파일입니다. ](https://github.com/GosuEE/trys-ketch-client/blob/dev/src/components/painting/CanvasWrapper.jsx)

```javascript
<Canvas
  isSubmitted={isSubmitted}
  ref={canvasRef}
  onClick={(event) => {
    if (eventState === EVENT_STATE.DRAWING || eventState === EVENT_STATE.ERASEING)
      drawCircle(ctx, event);
  }}
  onMouseDown={(event) => {
    history.push(ctx.getImageData(0, 0, ctx.canvas.width, ctx.canvas.height));
    historyPointer.current += 1;
    history.splice(historyPointer.current);
    if (eventState === EVENT_STATE.DRAWING || eventState === EVENT_STATE.ERASEING) {
      startDrawing(setIsDrawing);
    }
    if (eventState === EVENT_STATE.FILL) {
      fill(canvasRef, setCtx, ctx, event);
    }
  }}
  onMouseUp={() => {
    if (eventState === EVENT_STATE.DRAWING || eventState === EVENT_STATE.ERASEING) {
      finishDrawing(setIsDrawing);
    }
  }}
  onMouseMove={(event) => {
    if (eventState === EVENT_STATE.DRAWING || eventState === EVENT_STATE.ERASEING) {
      drawing(ctx, isDrawing, event);
    }
  }}
  onMouseLeave={() => {
    if (eventState === EVENT_STATE.DRAWING || eventState === EVENT_STATE.ERASEING) {
      finishDrawing(setIsDrawing);
    }
  }}
/>
```

현재 event의 상태를 'eraser', 'drawing', 'fill'로 나누어 해당 state마다 다른 함수가 호출되게 구현했습니다.

## webRTC

[ 시그널링 서버와 통신해 P2P webRTC연결을 진행하는 소스코드입니다. ](https://github.com/GosuEE/trys-ketch-client/blob/dev/src/components/webRTC/AudioCall.tsx)

### how to connect?

webRTC는 다음과 같은 절차를 밟아 진행됩니다.

1. 각 브라우저가 P2P 커뮤니케이션에 동의

2. 서로의 주소를 공유

3. 보안 사항 및 방화벽 우회

4. 멀티미디어 데이터를 실시간으로 교환

일반적인 웹 환경에서는 2번과 3번 문제를 해결하기는 조금 어렵습니다. webRTC는 브라우저에서 작동되기 때문에 외부에서 접근할 수 있는 주소가 없기 때문입니다. 따라서 통신 설정 초기 단계에서는 연결을 중재할 수 있는 서버가 필요합니다.

<b>TURN, STUN</b>

일반적인 컴퓨터에는 공인 IP가 할당되어있지 않습니다. 방화벽이나 NAT, DHCP 때문입니다. 일반적인 환경에서는 라우터가 NAT역할을 하여 내부 네트워크의 사설 IP들을 적절히 매핑시켜줍니다. 따라서 두 브라우저가 직접 통신을 하기 위해서는 현재 연결된 라우터의 공인 IP주소와 포트를 먼저 알아야합니다.

하지만 어떤 라우터들은 방화벽 설정이 되어있어 특정 주소나 포트와의 연결을 차단합니다. 이처럼 라우터를 통과하여 연결할 방법을 찾는 과정을 NAT traversal이라고 합니다. webRTC는 이를 STUN, TURN서버를 통해 구현하였습니다.

STUN방식은 단말이 자신의 공인 IP주소와 포트를 확인하는 프로토콜입니다. webRTC연결을 시작하기 전에 STUN서버를 향해 요청을 보내면 STUN서버는 NAT뒤에 있는 Peer들이 연결할 수 있도록 공인 IP주소와 포트를 찾아줍니다.

그러나 모든 단말들이 항상 자신의 정보를 찾아낼 수는 없습니다. 이런 경우 TURN이라는 서버를 매개로 통신하게됩니다. TURN방식의 경우 서버가 네트워크 미디어를 중개하게 되므로 진정한 P2P통신은 아닙니다. 따라서 최후의 수단으로 선택해야 합니다.

<b>ICE, Candidate</b>

STUN, TURN서버를 이용해 획득한 IP주소, 프로토콜, 포트의 조합으로 구성된 연결 가능한 네트워크 주소들을 Candidate라고 부릅니다. 그리고 위와 같은 과정을 후보 찾기라고 부릅니다.

후보들을 수집하면 일반적으로 3개의 주소를 얻게 됩니다.

1. 자신의 사설 IP와 포트 넘버

2. 자신의 공인 IP와 포트 넘버 (STUN, TURN 서버로부터 획득 가능)

3. TURN 서버의 IP와 포트 넘버 (TURN 서버를 사용하는 경우)

이 모든 과정은 ICE(Interactive Connectivity Establishment)라는 프레임워크 위에서 이루어집니다. ICE는 두 개의 단말이 P2P연결을 가능하게 하도록 최적의 경로를 찾아주는 프레임워크입니다.

즉, ICE 프레임워크가 STUN 또는 TURN서버를 이용해 상대방과 연결 가능한 후보들을 갖고 있게 됩니다. 이제 주소는 다 알았으니, 미디어와 관련된 정보를 교환해야 합니다.

<b>SDP</b>

SDP(Session Description Protocol)는 webRTC에서 스트리밍 미디어의 해상도나 형식, 코덱등의 초기 인수를 설명하기 위해 채택한 프로토콜입니다.

발행/ 구독 모델과 유사한 제안/응답 모델을 사용합니다. 어떤 피어가 미디어스트림을 교환할 것이라고 제안하면, 상대방으로부터 응답이 오기를 기다립니다.

응답을 받게 되면 각자의 피어가 수집한 ICE후보들에게 패킷을 보내고 가장 지연 시간이 적고 안정적인 경로를 결정합니다. 이렇게 최적의 ICE 후보가 선택되면 필요한 메타데이터와 IP주소, 포트, 미디어정보에 대한 피어간 합의가 완료되고 연결이 활성화됩니다.

만약 최선의 ICE 후보를 찾지 못한다면, 풀백으로 설정한 TURN서버를 사용합니다.

위 과정을 일컬어 시그널링이라고 부릅니다. 해당 프로젝트에서는 Spring boot로 시그널링 서버를 구현했으며, 서버와의 통신은 SockJS를 사용했습니다.

<b>출처: https://wormwlrm.github.io/2021/01/24/Introducing-WebRTC.html</b>







































